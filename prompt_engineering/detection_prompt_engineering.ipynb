{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Prompt Engineering\n",
    "## Construct Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample scenario 1 dataset\n",
    "label_example_map_1 = {}\n",
    "label_example_map_1['user bullies the bully'] = [\n",
    "    \"No one wants to hear from you Emma!\",\n",
    "    \"You are so pathetic Emma!\"\n",
    "]\n",
    "label_example_map_1['user bullies the victim'] = [\n",
    "    \"Haha Emma is right! Nobody wants to hear from you, Dylan!\",\n",
    "    \"Those shoes are lame and no one wants to see them!\"\n",
    "]\n",
    "label_example_map_1['user asks a question'] = [\n",
    "    \"How should I let Dylan know that I want to support him without hurting Emma?\",\n",
    "    \"What is the most appropriate way to respond to this situation?\"\n",
    "]\n",
    "label_example_map_1['user responds appropriately to bully'] = [\n",
    "    \"Emma, it is not right to say those words!\",\n",
    "    \"Stop being mean to Dylan!\"\n",
    "]\n",
    "label_example_map_1['user comforts victim'] = [\n",
    "    \"Dylan, don't listen to Emma, your shoes look fantastic!\",\n",
    "    \"Wow Dylan, I wish I could have those amazing shoes!\"\n",
    "]\n",
    "label_example_map_1['user says something irrelevant'] = [\n",
    "    \"I ate a lot today. How about you?\",\n",
    "    \"Give my new pet a name!\"\n",
    "]\n",
    "\n",
    "# sample scenario 2 dataset\n",
    "label_example_map_2 = {}\n",
    "label_example_map_2['user bullies the bully'] = [\n",
    "    \"Why don’t you look at yourself in the mirror and see how fat you are, Drake?\",\n",
    "    \"It’s so funny how a pig will call others pig!\"\n",
    "]\n",
    "label_example_map_2['user bullies the victim'] = [\n",
    "    \"You are indeed a pig Grace!\",\n",
    "    \"It doesn’t matter how much weight you lost, Grace, because no one cares about you!\"\n",
    "]\n",
    "label_example_map_2['user asks a question'] = [\n",
    "    \"What's the best way to communicate to Grace that I'm here to support her without hurting Drake in the process?\",\n",
    "    \"What is a better way to respond in this situation?\"\n",
    "]\n",
    "label_example_map_2['user responds appropriately to bully'] = [\n",
    "    \"Drake, you shouldn’t be this rude to Grace.\",\n",
    "    \"Drake, you should apologize to Grace for your words.\"\n",
    "]\n",
    "label_example_map_2['user comforts victim'] = [\n",
    "    \"Grace, your efforts to lose weight will pay off!\",\n",
    "    \"Grace, I like how self-disciplined you are! But don’t feel so much pressure! You already look great!\"\n",
    "]\n",
    "label_example_map_2['user says something irrelevant'] = [\n",
    "    \"How’s the weather today?\",\n",
    "    \"What’s your favorite song?\"\n",
    "]\n",
    "\n",
    "# sample scenario 3 dataset\n",
    "label_example_map_3 = {}\n",
    "label_example_map_3['user bullies the bully'] = [\n",
    "    \"Let’s post an embarrassing photo of your's so you will know how it feels being disrespected!\",\n",
    "    \"Look at yourself first, Chandler!\"\n",
    "]\n",
    "label_example_map_3['user bullies the victim'] = [\n",
    "    \"Haha Monica looks so hilarious!\",\n",
    "    \"I’m gonna repost this so that everyone will know how funny Monica looks in this pic!\"\n",
    "]\n",
    "label_example_map_3['user asks a question'] = [\n",
    "    \"How should I tell Chandler to stop making fun of Monica?\",\n",
    "    \"What should I say to stop this bully?\"\n",
    "]\n",
    "label_example_map_3['user responds appropriately to bully'] = [\n",
    "    \"Chandler, it’s not funny if Monica doesn’t feel like it’s funny. You should delete this post!\",\n",
    "    \"Chandler, you should apologize to Monica for your actions!\"\n",
    "]\n",
    "label_example_map_3['user comforts victim'] = [\n",
    "    \"Monica, don’t worry, I’m on the same side as you.\",\n",
    "    \"Monica, everyone has embarrassing moments. I can also show you mine if that makes you feel better!\"\n",
    "]\n",
    "label_example_map_3['user says something irrelevant'] = [\n",
    "    \"I wonder whether it will rain today!\",\n",
    "    \"How can I make myself a hamburger?\"\n",
    "]\n",
    "\n",
    "label_example_maps = [label_example_map_1, label_example_map_2, label_example_map_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "def prompt_gpt(prompt):\n",
    "    load_dotenv()\n",
    "    openai.api_key = os.getenv('API_KEY')\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=32\n",
    "    )\n",
    "    return response['choices'][0]['text']\n",
    "\n",
    "def list_categories(label_example_map):\n",
    "    result = ''\n",
    "    for category in label_example_map.keys():\n",
    "        result += f'\"{category}\", '\n",
    "    return result[:result.rindex(',')]\n",
    "\n",
    "def format_response(response):\n",
    "    return response.lower().strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot with no context\n",
    "The prompt only includes instructions. It does not include context or examples. The prompt format is as follows:  \n",
    "\n",
    "Classify the user input into one of the following categories: [category_1], . . ., [category_n]  \n",
    "Input: [input text to be classified]  \n",
    "Category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: No one wants to hear from you Emma!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "example: You are so pathetic Emma!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "example: Stop being mean to Dylan!\n",
      "correct prediction: user responds appropriately to bully\n",
      "misprediction: user bullies the bully\n",
      "\n",
      "\n",
      "example: Wow Dylan, I wish I could have those amazing shoes!\n",
      "correct prediction: user comforts victim\n",
      "misprediction: user says something irrelevant\n",
      "\n",
      "\n",
      "example: I ate a lot today. How about you?\n",
      "correct prediction: user says something irrelevant\n",
      "misprediction: user asks a question\n",
      "\n",
      "\n",
      "example: Give my new pet a name!\n",
      "correct prediction: user says something irrelevant\n",
      "misprediction: user asks a question\n",
      "\n",
      "\n",
      "example: Why don’t you look at yourself in the mirror and see how fat you are, Drake?\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "example: It’s so funny how a pig will call others pig!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user says something irrelevant\n",
      "\n",
      "\n",
      "example: How’s the weather today?\n",
      "correct prediction: user says something irrelevant\n",
      "misprediction: user asks a question\n",
      "\n",
      "\n",
      "example: What’s your favorite song?\n",
      "correct prediction: user says something irrelevant\n",
      "misprediction: user asks a question\n",
      "\n",
      "\n",
      "example: Let’s post an embarrassing photo of your's so you will know how it feels being disrespected!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "example: Look at yourself first, Chandler!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user responds appropriately to bully\n",
      "\n",
      "\n",
      "example: Haha Monica looks so hilarious!\n",
      "correct prediction: user bullies the victim\n",
      "misprediction: user says something irrelevant\n",
      "\n",
      "\n",
      "example: I wonder whether it will rain today!\n",
      "correct prediction: user says something irrelevant\n",
      "misprediction: user asks a question\n",
      "\n",
      "\n",
      "example: How can I make myself a hamburger?\n",
      "correct prediction: user says something irrelevant\n",
      "misprediction: user asks a question\n",
      "\n",
      "\n",
      "Accuracy: 21/36\n",
      "Number of hallucinations: 0\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_hallucinations = 0\n",
    "total = 0\n",
    "\n",
    "for label_example_map in label_example_maps:\n",
    "    categories_list = list_categories(label_example_map)\n",
    "    for correct_label in label_example_map.keys():\n",
    "        examples = label_example_map[correct_label]\n",
    "        for example in examples:\n",
    "            prompt = f'Classify the user input into one of the following categories: {categories_list}\\nInput: {example}\\nCategory: '\n",
    "            predicted_label = format_response(prompt_gpt(prompt))\n",
    "            total += 1\n",
    "            if predicted_label not in label_example_map.keys():\n",
    "                num_hallucinations += 1\n",
    "                print(f'example: {example}')\n",
    "                print(f'correct prediction: {predicted_label}')\n",
    "                print(f'hallucinated prediction: {predicted_label}')\n",
    "                print('\\n')\n",
    "            elif predicted_label != correct_label:\n",
    "                print(f'example: {example}')\n",
    "                print(f'correct prediction: {correct_label}')\n",
    "                print(f'misprediction: {predicted_label}')\n",
    "                print('\\n')\n",
    "            else:\n",
    "                num_correct += 1\n",
    "print(f'Accuracy: {num_correct}/{total}')\n",
    "print(f'Number of hallucinations: {num_hallucinations}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "- Context is helpful: The classifier struggled to distinguish \"user bullies the bully\" from \"user bullies the victim\". This is likely because it did not have access to the context and thus could not differentiate between bullies and victims.\n",
    "- Class names matter: Both examples for \"user says something irrelevant\" were labeled as \"user asks a question\" since both irrelevant examples were in the form of questions. This shows that the LLM can understand the class names, so making them precise and distinguishable from each other is important.\n",
    "- Hallucinations appear to not be an issue when the prompt is well-designed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot with context\n",
    "The prompt includes instructions and context. It does not include examples. The prompt format is as follows:  \n",
    "\n",
    "Given the context, classify the user input into one of the following categories: [category_1], . . ., [category_n]  \n",
    "Context: [context from social media platform]  \n",
    "Input: [input text to be classified]  \n",
    "Category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: You are so pathetic Emma!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "example: Wow Dylan, I wish I could have those amazing shoes!\n",
      "correct prediction: user comforts victim\n",
      "misprediction: user responds appropriately to bully\n",
      "\n",
      "\n",
      "example: It’s so funny how a pig will call others pig!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user says something irrelevant\n",
      "\n",
      "\n",
      "example: Look at yourself first, Chandler!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user responds appropriately to bully\n",
      "\n",
      "\n",
      "example: Haha Monica looks so hilarious!\n",
      "correct prediction: user bullies the victim\n",
      "misprediction: user says something irrelevant\n",
      "\n",
      "\n",
      "Accuracy: 31/36\n",
      "Number of hallucinations: 0\n"
     ]
    }
   ],
   "source": [
    "contexts = [\n",
    "    'Social Media Post by Dylan: “Wow, look at these new awesome kicks!\" Social Media Comment by Emma: “When will you get it into your head that nobody wants to hear from you!',\n",
    "    'Social Media Post by Grace: “First day on diet!\" Social Media Comment by Drake: “You are as fat as a pig, you can never lose another pound!',\n",
    "    'Social Media Post by Chandler (posted an embarrassing photo of Monica): “Haha look how funny Monica is in this pic!\" Social Media Comment by Monica: “This is not funny at all!”'\n",
    "]\n",
    "\n",
    "num_correct = 0\n",
    "num_hallucinations = 0\n",
    "total = 0\n",
    "\n",
    "for label_example_map, context in zip(label_example_maps, contexts):\n",
    "    categories_list = list_categories(label_example_map)\n",
    "    for correct_label in label_example_map.keys():\n",
    "        examples = label_example_map[correct_label]\n",
    "        for example in examples:\n",
    "            prompt = f'Given the context, classify the user input into one of the following categories: {categories_list}\\nContext: {context}\\nInput: {example}\\nCategory: '\n",
    "            predicted_label = format_response(prompt_gpt(prompt))\n",
    "            total += 1\n",
    "            if predicted_label not in label_example_map.keys():\n",
    "                num_hallucinations += 1\n",
    "                print(f'example: {example}')\n",
    "                print(f'correct prediction: {predicted_label}')\n",
    "                print(f'hallucinated prediction: {predicted_label}')\n",
    "                print('\\n')\n",
    "            elif predicted_label != correct_label:\n",
    "                print(f'example: {example}')\n",
    "                print(f'correct prediction: {correct_label}')\n",
    "                print(f'misprediction: {predicted_label}')\n",
    "                print('\\n')\n",
    "            else:\n",
    "                num_correct += 1\n",
    "print(f'Accuracy: {num_correct}/{total}')\n",
    "print(f'Number of hallucinations: {num_hallucinations}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "- Context is helpful: As was suggested by the previous test, context is very helpful. Adding the context to the prompt increased the accuracy from 21/36 to 31/36. However, including the context could be difficult to implement in our system, because the context can come in many different forms and dynamically change based on actions that the user takes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot with no context\n",
    "The prompt includes instructions and examples. It does not include context. The prompt format is as follows:  \n",
    "\n",
    "Classify the user inputs into one of the following categories: [category_1], . . ., [category_n]  \n",
    "Input 1: [example input 1]  \n",
    "Category 1: [example category 1]  \n",
    "Input 2: [example input 2]  \n",
    "Category 2: [example category 2]  \n",
    ".  \n",
    ".  \n",
    ".  \n",
    "Input 2n: [example input 2n]  \n",
    "Category 2n: [example category 2n]  \n",
    "Input 2n+1: [input text to be classified]  \n",
    "Category 2n+1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: You are so pathetic Emma!\n",
      "correct prediction: user bullies the bully\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "example: Wow Dylan, I wish I could have those amazing shoes!\n",
      "correct prediction: user comforts victim\n",
      "misprediction: user bullies the victim\n",
      "\n",
      "\n",
      "Accuracy: 34/36\n",
      "Number of hallucinations: 0\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = {}\n",
    "few_shot_examples['user bullies the bully'] = [\n",
    "    \"Just leave him alone! No one likes you anyways!\",\n",
    "    \"I wish someone would bully you for a change!\"\n",
    "]\n",
    "few_shot_examples['user bullies the victim'] = [\n",
    "    \"I could not agree more. Your fashion has always been terrible!\",\n",
    "    \"Dylan is such a loser and will never be popular\"\n",
    "]\n",
    "few_shot_examples['user asks a question'] = [\n",
    "    \"How can I support the victim without offending the bully?\",\n",
    "    \"Do you have any ideas on how I should respond?\"\n",
    "]\n",
    "few_shot_examples['user responds appropriately to bully'] = [\n",
    "    \"Please leave her alone. She did nothing wrong.\",\n",
    "    \"You are being disrespectful and should consider how you would feel if you were being bullied.\"\n",
    "]\n",
    "few_shot_examples['user comforts victim'] = [\n",
    "    \"Don't listen to them, they don't know what they're talking about\",\n",
    "    \"You aren't a loser at all! Let's hang out this weekend\"\n",
    "]\n",
    "few_shot_examples['user says something irrelevant'] = [\n",
    "    \"What time is it?\",\n",
    "    \"I am so tired right now\"\n",
    "]\n",
    "\n",
    "num_correct = 0\n",
    "num_hallucinations = 0\n",
    "total = 0\n",
    "\n",
    "prompt_instruction_and_examples = f'Classify the user inputs into one of the following categories: {categories_list}\\n'\n",
    "example_num = 0\n",
    "for category in few_shot_examples.keys():\n",
    "    for few_shot_example in few_shot_examples[category]:\n",
    "        example_num += 1\n",
    "        prompt_instruction_and_examples += f'Input {example_num}: {few_shot_example}\\n'\n",
    "        prompt_instruction_and_examples += f'Category {example_num}: {category}\\n'\n",
    "\n",
    "for label_example_map in label_example_maps:\n",
    "    categories_list = list_categories(label_example_map)\n",
    "    for correct_label in label_example_map.keys():\n",
    "        examples = label_example_map[correct_label]\n",
    "        prompt_examples = few_shot_examples[correct_label]\n",
    "        for example in examples:\n",
    "            prompt = prompt_instruction_and_examples + f'Input {example_num+1}: {example}\\nCategory {example_num+1}: '\n",
    "            predicted_label = format_response(prompt_gpt(prompt))\n",
    "            total += 1\n",
    "            if predicted_label not in label_example_map.keys():\n",
    "                num_hallucinations += 1\n",
    "                print(f'example: {example}')\n",
    "                print(f'correct prediction: {predicted_label}')\n",
    "                print(f'hallucinated prediction: {predicted_label}')\n",
    "                print('\\n')\n",
    "            elif predicted_label != correct_label:\n",
    "                print(f'example: {example}')\n",
    "                print(f'correct prediction: {correct_label}')\n",
    "                print(f'misprediction: {predicted_label}')\n",
    "                print('\\n')\n",
    "            else:\n",
    "                num_correct += 1\n",
    "print(f'Accuracy: {num_correct}/{total}')\n",
    "print(f'Number of hallucinations: {num_hallucinations}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "- Examples are helpful: Performance increased here despite not having any context. This was a bit surprising, because the model still needed to know how to distinguish bullies from victims and relevant questions from irrelevant questions. This suggests that with good examples for each class, the classifier can do well without context.\n",
    "- Nuanced classes still challenging: Both misclassifications were between \"user bullies the bully\" and \"user bullies the victim\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Instructions with context and few-shot examples with no context performed significantly better than instructions alone. Because few-shot examples performed slightly better and, more importantly, extracting the context from the UI could be quite difficult, using few-shot examples for the prompts could be best. If we decide to do this, more experimentation should be done to find the optimal number of examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
